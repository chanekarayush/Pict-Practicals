{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e24de06a-499b-4047-bb31-d46966ea136d",
   "metadata": {},
   "source": [
    "# Assignment 3\n",
    "## Roll no. `41313`\n",
    "### Hebbian Learning\n",
    "\n",
    "### **Problem Statement**\n",
    "Implement basic logic gates using Hebbnet neural networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fe43564-3897-4cd0-91c8-c41ac8c12551",
   "metadata": {},
   "source": [
    "#### Hebbian learning follows the principle:\n",
    "\n",
    "> **“Neurons that fire together, wire together.”**\n",
    "\n",
    "In the simplest form, the **weight update rule** is:\n",
    "\n",
    "$$\n",
    "w_{ij} = w_{ij} + \\eta \\cdot x_i \\cdot y\n",
    "$$\n",
    "\n",
    "* $x_i$ → input\n",
    "* $y$ → output (desired target or actual neuron output)\n",
    "* $\\eta$ → learning rate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9831bbf-4d65-4b73-b4ca-3a72f72cf701",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b9542ae-a0b8-4107-96a4-2426db45feec",
   "metadata": {},
   "source": [
    "## 1. Creating the HebbNet Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c8f69bd2-1206-4324-b74c-b225b7d03379",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HebbNet:\n",
    "    def __init__(self, input_size, lr=1.0):\n",
    "        self.weights = np.zeros(input_size)\n",
    "        self.bias = 0\n",
    "        self.lr = lr\n",
    "\n",
    "    def train(self, X, Y):\n",
    "        for x, y in zip(X, Y):\n",
    "            self.weights += self.lr * x * y\n",
    "            self.bias += self.lr * y\n",
    "\n",
    "    def predict(self, x):\n",
    "        activation = np.dot(self.weights, x) + self.bias\n",
    "        return 1 if activation > 0 else -1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07e0262a-a7b7-4925-a893-4823b92bb44b",
   "metadata": {},
   "source": [
    "## 2. Defining the `binary` to `bipolar` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "77e80fc1-7637-4b3e-b53f-faf62a6a9722",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert binary {0,1} → bipolar {-1,1}\n",
    "def bipolar(x):\n",
    "    return np.where(x==0, -1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "def88630-b60a-46fb-ac7e-c689428fe8c9",
   "metadata": {},
   "source": [
    "## Training `AND` Gate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce9d126f-6b3e-4571-8ba5-1e2f0361c0df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Train AND gate ---\n",
    "X = np.array([[0,0],[0,1],[1,0],[1,1]])\n",
    "Y_and = np.array([0,0,0,1])\n",
    "\n",
    "Xb = bipolar(X)  # inputs in bipolar form\n",
    "Yb_and = bipolar(Y_and)\n",
    "\n",
    "hebb_and = HebbNet(input_size=2)\n",
    "hebb_and.train(Xb, Yb_and)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "336dbf2f-ea88-4e40-9c1b-83339a01d9b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AND Gate Results:\n",
      "Input: [-1 -1] -> Predicted: -1 , Target: 0\n",
      "Input: [-1  1] -> Predicted: -1 , Target: 0\n",
      "Input: [ 1 -1] -> Predicted: -1 , Target: 0\n",
      "Input: [1 1] -> Predicted: 1 , Target: 1\n"
     ]
    }
   ],
   "source": [
    "print(\"AND Gate Results:\")\n",
    "for x, y in zip(Xb, Y_and):\n",
    "    print(f\"Input: {x} -> Predicted: {hebb_and.predict(x)} , Target: {y}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82617845-597d-42d0-9a6d-2bea4696d49b",
   "metadata": {},
   "source": [
    "## Training `OR` Gate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "feff2dc8-91b5-4a9b-9cb7-ff6deb0639b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Train OR gate ---\n",
    "Y_or = np.array([0,1,1,1])\n",
    "Yb_or = bipolar(Y_or)\n",
    "\n",
    "hebb_or = HebbNet(input_size=2)\n",
    "hebb_or.train(Xb, Yb_or)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2a6f0bba-ee27-46e6-9a09-5941f14fe4b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OR Gate Results:\n",
      "Input: [-1 -1] -> Predicted: -1 , Target: 0\n",
      "Input: [-1  1] -> Predicted: 1 , Target: 1\n",
      "Input: [ 1 -1] -> Predicted: 1 , Target: 1\n",
      "Input: [1 1] -> Predicted: 1 , Target: 1\n"
     ]
    }
   ],
   "source": [
    "print(\"OR Gate Results:\")\n",
    "for x, y in zip(Xb, Y_or):\n",
    "    print(f\"Input: {x} -> Predicted: {hebb_or.predict(x)} , Target: {y}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0412853c-31ec-4bd8-9228-a4d581372abb",
   "metadata": {},
   "source": [
    "## Training `NOT` Gate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "85f00eb9-7c90-433b-aa12-7e62fbbece99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Train NOT gate ---\n",
    "X_not = np.array([[0],[1]])\n",
    "Y_not = np.array([1,0])\n",
    "\n",
    "Xb_not = bipolar(X_not)\n",
    "Yb_not = bipolar(Y_not)\n",
    "\n",
    "hebb_not = HebbNet(input_size=1)\n",
    "hebb_not.train(Xb_not, Yb_not)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "82b51a3b-2f99-400a-a130-6a6fd204e387",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOT Gate Results:\n",
      "Input: [-1] -> Predicted: 1 , Target: 1\n",
      "Input: [1] -> Predicted: -1 , Target: 0\n"
     ]
    }
   ],
   "source": [
    "print(\"NOT Gate Results:\")\n",
    "for x, y in zip(Xb_not, Y_not):\n",
    "    print(f\"Input: {x} -> Predicted: {hebb_not.predict(x)} , Target: {y}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00461aed-b0d0-4d87-8aac-a93a956b593d",
   "metadata": {},
   "source": [
    "#### Note: XOR cannot be learned by a single-layer Hebbnet (not linearly separable). \n",
    "*Also it is not considered a basic gate as XOR can be constructed using `AND`, `OR` and `NOT` gates*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
